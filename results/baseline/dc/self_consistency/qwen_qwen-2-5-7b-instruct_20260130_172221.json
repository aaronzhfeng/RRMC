[
  {
    "idx": 0,
    "pred": 0,
    "label": 3,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 1,
    "pred": 0,
    "label": 0,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 2,
    "pred": 0,
    "label": 1,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "A",
      "A",
      "E",
      "A",
      "A",
      "E",
      "A",
      "A"
    ],
    "mi_scores": [
      0.25
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.25,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 3,
    "pred": 3,
    "label": 4,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 4,
    "pred": 0,
    "label": 2,
    "record": [
      {
        "turn": 1,
        "suspect": "Mr. Jonathan Reed",
        "question": "What were you doing with the antique marble bust around 7pm last evening?",
        "feedback": "Around 7pm, I was helping Dr. Eleanor Blackwood set up her presentation materials near the antique marble bust."
      }
    ],
    "round": 2,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A"
    ],
    "mi_scores": [
      0.375,
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.375,
        "should_stop": false,
        "reason": "low_consistency"
      },
      {
        "turn": 2,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 5,
    "pred": 3,
    "label": 3,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 6,
    "pred": 1,
    "label": 1,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "B",
      "B",
      "B",
      "B",
      "B",
      "B",
      "B",
      "B"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 7,
    "pred": 2,
    "label": 4,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 8,
    "pred": 3,
    "label": 0,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 9,
    "pred": 0,
    "label": 1,
    "record": [
      {
        "turn": 1,
        "suspect": "Sebastian Whitaker",
        "question": "What were you doing between 9pm and 10pm last night?",
        "feedback": "I was just standing by the entrance, trying to look calm while guests approached me, asking about my artwork."
      }
    ],
    "round": 2,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A",
      "A"
    ],
    "mi_scores": [
      0.375,
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.375,
        "should_stop": false,
        "reason": "low_consistency"
      },
      {
        "turn": 2,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 10,
    "pred": 1,
    "label": 3,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "B",
      "B",
      "B",
      "B",
      "B",
      "D",
      "D",
      "B"
    ],
    "mi_scores": [
      0.25
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.25,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 11,
    "pred": 2,
    "label": 2,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 12,
    "pred": 3,
    "label": 1,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 13,
    "pred": 3,
    "label": 1,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 14,
    "pred": 2,
    "label": 3,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 15,
    "pred": 4,
    "label": 4,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "E",
      "E",
      "E",
      "E",
      "E",
      "E",
      "E",
      "E"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 16,
    "pred": 3,
    "label": 1,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 17,
    "pred": 2,
    "label": 0,
    "record": [],
    "round": 1,
    "correctness": false,
    "raw_pred": "",
    "raw_samples": [
      "C",
      "C",
      "C",
      "A",
      "A",
      "C",
      "C",
      "C"
    ],
    "mi_scores": [
      0.25
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.25,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 18,
    "pred": 2,
    "label": 2,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C",
      "C"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  },
  {
    "idx": 19,
    "pred": 3,
    "label": 3,
    "record": [],
    "round": 1,
    "correctness": true,
    "raw_pred": "",
    "raw_samples": [
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D",
      "D"
    ],
    "mi_scores": [
      0.0
    ],
    "decisions": [
      {
        "turn": 1,
        "score": 0.0,
        "should_stop": true,
        "reason": "high_consistency"
      }
    ]
  }
]